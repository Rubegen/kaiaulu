---
title: "Causal Analysis of Architectural Flaw and Outcome Metrics"
output: 
  html_document:
    toc: true
    number_sections: true
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Causal Analysis of Architectural Flaw and Outcome Metrics}
  %\VignetteEncoding{UTF-8}
---

```{r}
rm(list = ls())
seed <- 1
set.seed(seed)
```

```{r warning=FALSE,message=FALSE}
require(kaiaulu)
require(visNetwork)
require(data.table)
require(stringi)
require(igraph)
require(gh)
require(yaml)
require(magrittr)
require(knitr)
```

```{r}
tool <- yaml::read_yaml("../tools.yml")
conf <- yaml::read_yaml("../conf/tse_apex.yml")
perceval_path <- tool[["perceval"]]
dv8_path <- tool[["dv8"]]

# Gitlog parameters
git_repo_path <- conf[["version_control"]][["log"]]

# Depends parameters
depends_jar_path <- tool[["depends"]]
language <- conf[["tool"]][["depends"]][["code_language"]]
keep_dependencies_type <- conf[["tool"]][["depends"]][["keep_dependencies_type"]]

# DV8 parameters 
project_path <- conf[["tool"]][["dv8"]][["folder_path"]]
project_name <- stringi::stri_split_regex(project_path,pattern = "/")[[1]]
project_name <- project_name[length(project_name)]

flaws_params <- conf[["tool"]][["dv8"]][["architectural_flaws"]]

# Filters
file_extensions <- conf[["filter"]][["keep_filepaths_ending_with"]]
substring_filepath <- conf[["filter"]][["remove_filepaths_containing"]]
filter_commit_size <- conf[["filter"]][["remove_filepaths_on_commit_size_greather_than"]]


# Issue ID Regex on Commit Messages
issue_id_regex <- conf[["commit_message_id_regex"]][["issue_id"]]
# Path to Jira Issues (obtained using `download_jira_data Notebook`)
jira_issues_path <- conf[["issue_tracker"]][["jira"]][["issues"]]

```

# Preparing Gitlog and Dependencies for DV8

Our first step is to parse the Git log and Dependencies for DV8. These will used to construct historical and structural dependencies in DV8. There are two ways to perform this step. The legacy approach is deferred to the end of this notebook for completeness sake, however does not allow for customizing the filtering step in Kaiaulu. 

## Git Log 

For the git log, we first parse it into Kaiaulu as a table, and filter based on the project configuration files criteria. Here's a sample:


```{r}
#git_repo_path <- "~/Downloads/testing-cochange/.git"
project_git <- parse_gitlog(perceval_path,git_repo_path)
project_git <- project_git  %>%
  filter_by_file_extension(file_extensions,"file_pathname")  %>% 
  filter_by_filepath_substring(substring_filepath,"file_pathname") %>% 
  filter_by_commit_size(commit_size = filter_commit_size)

kable(head(project_git))
```

Checking the git log last timestamp is also advised, as git logs on GitHub are sometimes mirrors which have not been updated for years (e.g. Geronimo's), or your local copy may not be up to date. 

```{r}
project_git[order(author_datetimetz)]$author_datetimetz[1]
```

Earliest Date:

```{r}
project_git[order(-author_datetimetz)]$author_datetimetz[1]
```



We then transform it as a hsdsm JSON (i.e. hdsmj):

```{r}
hdsmj_path <- transform_gitlog_to_hdsmj(project_git,
                                        hdsmj_path = file.path(project_path,paste0(project_name,"-hdsm.json")))
```


Next, we parse file dependencies using Depends, filter the files by the project configuration file criteria, and proceed to convert it into a DV8 Structural Dependency Matrix binary. 

```{r}
project_dependencies <- parse_dependencies(depends_jar_path,git_repo_path,language=language)

project_dependencies[["nodes"]] <- project_dependencies[["nodes"]]  %>%
  filter_by_file_extension(file_extensions,"filepath")  %>% 
  filter_by_filepath_substring(substring_filepath,"filepath")

project_dependencies[["edgelist"]] <- project_dependencies[["edgelist"]]  %>%
  filter_by_file_extension(file_extensions,"src_filepath")  %>% 
  filter_by_file_extension(file_extensions,"dest_filepath")  %>% 
  filter_by_filepath_substring(substring_filepath,"src_filepath") %>%
  filter_by_filepath_substring(substring_filepath,"dest_filepath")


sdsmj_path <- transform_dependencies_to_sdsmj(project_dependencies,
                                    sdsmj_path = file.path(project_path,paste0(project_name,"-sdsm.json")))

list.files(project_path)
```



# Converting to DV8 Binaries

We are now ready to convert the json files into binary format, so they can be merged:

```{r}

hdsmb_path <- dv8_dsmj_to_dsmb(dv8_path = dv8_path,
                                     dsmj_path = hdsmj_path, 
                                     dsmb_path = file.path(project_path,paste0(project_name,
                                                                               "-hdsm.dv8-dsm")))

sdsmb_path <- dv8_dsmj_to_dsmb(dv8_path = dv8_path,
                                     dsmj_path = sdsmj_path, 
                                     dsmb_path = file.path(project_path,paste0(project_name,
                                                                               "-sdsm.dv8-dsm")))

list.files(project_path)
```


# Merging DSMs

Our next step in the pipeline, is to combine both our binary DSMs, i.e. \*-sdsm.dv8-dsm and \*-hdsm.dv8-dsm into a merged DSM, \*-merge-dv8.dsm. 

```{r}
mdsmb_path <- dv8_hdsmb_sdsmb_to_mdsmb(dv8_path=dv8_path,
                                         hdsmb_path=hdsmb_path,
                                         sdsmb_path = sdsmb_path,
                                         mdsmb_path = file.path(project_path,
                                                                paste0(project_name,"-merge.dv8-dsm")))
list.files(project_path)
```

## Exploring Merge DSMs

We can load load on DV8-GUI the -hdsm, -sdsm or -mdsm files files to inspect their matrices, or export them via dv8-console their 
.xlsx counterpart. Let's inspect the -mdsm. First, we will perform clustering over the files. This will later be displayed in the DSM as black rectangles. This is an optional step:

```{r}
hierclsxb_path <- dv8_mdsmb_to_hierclsxb(dv8_path = dv8_path,
                                          mdsmb_path = mdsmb_path,
                                          hierclsxb_path = file.path(project_path,
                                                                     paste0(project_name,
                                                                            "-clsx.dv8-clsx")))
list.files(project_path)
```

# DV8 Analysis

Now we have a merged DSM, we can perform various analysis in DV8. 

## Architectural Flaws 

DV8 computes a variety of metrics. Let's first observe Architectural Flaws. 

```{r}
# Format Architectural Flaw Parameters to DV8 Command
flaws_params$cliqueDepends <- stringi::stri_c(flaws_params$cliqueDepends,collapse=",")
flaws_params$uihDepends <- stringi::stri_c(flaws_params$uihDepends,collapse=",")
flaws_params$uihInheritance <- stringi::stri_c(flaws_params$uihInheritance,collapse=",")


flaws_folder <- dv8_mdsmb_to_flaws(dv8_path = dv8_path, 
                                    mdsmb_path = mdsmb_path,
                                    flaws_path = file.path(project_path,paste0(project_name,"_flaws")),
                                    cliqueDepends=flaws_params$cliqueDepends,
                                    crossingCochange=flaws_params$crossingCochange,
                                    crossingFanIn=flaws_params$crossingFanIn,
                                    crossingFanOut=flaws_params$crossingFanOut,
                                    mvCochange=flaws_params$mvCochange,
                                    uiCochange=flaws_params$uiCochange,
                                    uihDepends=flaws_params$uihDepends,
                                    uihInheritance=flaws_params$uihInheritance,
                                    uiHistoryImpact=flaws_params$uiHistoryImpact,
                                    uiStructImpact=flaws_params$uiStructImpact)
list.files(project_path)
```


### Exploring Flaws DSMs 

We can see a folder of Architectural Flaws was generated. The folder organization provides us with means to understand what files are assigned to various types of architectural flaws. The following is a general  example used for geronimo (not computed here, but the structure carries over for other larger projects):

```
geronimo_flaws/
├── modularity-violation
└── package-cycle
```

Describes two types of architectural flaws were found in APR, modularity violation and package-cycle. Moreover inside each of the folders we see numbered folders:

```
geronimo_flaws/
├── modularity-violation
│   ├── 1
│   │   ├── 1-clsx.dv8-clsx
│   │   ├── 1-hdsm.dv8-dsm
│   │   ├── 1-merge.dv8-dsm
│   │   ├── 1-sdsm.dv8-dsm
│   │   └── 1.dv8-issue
│   ├── 10
│   │   ├── 10-clsx.dv8-clsx
│   │   ├── 10-hdsm.dv8-dsm
│   │   ├── 10-merge.dv8-dsm
│   │   ├── 10-sdsm.dv8-dsm
│   │   └── 10.dv8-issue
```

Each numbered folder represents an architectural flaw ID. For example, above we have the modularity violation flaws ID 1 and ID 10. We can further see the sdsm, hdsm, merge dsm, and cluster files occur within both folder ids. If load on DV8 GUI or export to excel (as done in the prior section) any of these files, we can see which files participate in these architectural flaws, and the clusters they are assigned. We will now see how to represent this information as a table we can parse in R, or more specifically the file-architectural flaw assignment, so it can be combined to other analysis in Kaiaulu.


### Creating a Flaws Mapping

```{r}
file_to_flaws_map <- parse_dv8_architectural_flaws(dv8_path, flaws_folder,progress_bar = TRUE)
fwrite(file_to_flaws_map,file.path(project_path,paste0(project_name,"-flaws_map.csv")))
kable(head(file_to_flaws_map))
```

```{r}
file_to_flaws_map <- fread(file.path(project_path,paste0(project_name,"-flaws_map.csv")))
```


```{r}
file_flaws <- file_to_flaws_map[,.(n_flaws=length(architecture_issue_id)),by=c("file_path",
                                                                 "architecture_issue_type")]
file_flaws <- dcast(file_flaws, file_path ~ ...,value.var = "n_flaws")
```


# Identifying Issue IDs in Commit Messages 

We can use a built-in Kaiaulu function to search for a regular expression (regex) of the issue id. First we use the regex to calculate how many commits contain issue ids. Ideally, you should consider projects with a high enough coverage, or the results may not be representative.

The total number of commits with issue ids in the chosen git slice is:

```{r}
commit_message_id_coverage(project_git,issue_id_regex)
```

Proportion of commit messages containing issue ids relative to all commits in the slice:

```{r}
normalized_coverage <- commit_message_id_coverage(project_git,issue_id_regex)/length(unique(project_git$commit_hash))
normalized_coverage
```

# Calculating Outcome Metrics

We will calculate four metrics:

 * **file bug frequency**: the total number of commits of all bug type issues the file was involved
 * **file bug churn**: the total churn sum of commits of all bug type issues the file was involved
 * **file non-bug frequency**: the total number of commits of all non-bug type issues the file was involved
 * **file non-bug churn:** the total churn sum of commits of all non-bug type issues the file was involved


First, we parse out of the `project_git`'s commit messages, the issue ids and add to a separate column. Note, as mentioned above, not every commit will have an issue anotated to it. 


```{r}
project_git <- parse_commit_message_id(project_git, issue_id_regex)
#jira_issues <- parse_jira(jira_issues_path)[["issues"]]

jira_issues <- parse_jira_rss_xml(jira_issues_path)
```


```{r}
file_churn <- metric_file_churn(project_git)
file_bug_frequency <- metric_file_bug_frequency(project_git,jira_issues)
file_non_bug_frequency <- metric_file_non_bug_frequency(project_git,jira_issues)
file_bug_churn <- metric_file_bug_churn(project_git,jira_issues)
file_non_bug_churn <- metric_file_non_bug_churn(project_git,jira_issues)


#kable(head(file_non_bug_frequency[order(-file_bug_frequency)],20))
```

# Merge

The left join table is the `project_dependencies` nodes table. Any other tables should be left joined to it, including git log ones. Otherwise, files no longer present in a snapshot will be included via the git log, which is incorrect. 


```{r}
flaws_and_outcomes_dt <- project_dependencies[["nodes"]]

setnames(flaws_and_outcomes_dt,
         old = "filepath",
         new = "file_pathname")

setnames(file_flaws,
         old = "file_path",
         new = "file_pathname")

flaws_and_outcomes_dt <- merge(flaws_and_outcomes_dt,file_flaws, by = "file_pathname", all.x = TRUE)
flaws_and_outcomes_dt <- merge(flaws_and_outcomes_dt,file_churn, by = "file_pathname", all.x = TRUE)
flaws_and_outcomes_dt <- merge(flaws_and_outcomes_dt,file_bug_frequency, by = "file_pathname", all.x = TRUE)
flaws_and_outcomes_dt <- merge(flaws_and_outcomes_dt,file_non_bug_frequency, by = "file_pathname", all.x = TRUE)
flaws_and_outcomes_dt <- merge(flaws_and_outcomes_dt,file_bug_churn, by = "file_pathname", all.x = TRUE)
flaws_and_outcomes_dt <- merge(flaws_and_outcomes_dt,file_non_bug_churn, by = "file_pathname", all.x = TRUE)
```

# Fill Non Join Match with 0s 

When combining tables, if a file was not listed in a metric calculated from the git log, it is because no file change was associated with the bug. The same is true in `file_flaws`: If the file was not assigned to an architectural flaw, it will not occur. 

```{r}
setnafill(flaws_and_outcomes_dt, 
          cols = colnames(flaws_and_outcomes_dt)[2:length(colnames(flaws_and_outcomes_dt))]
          , fill = 0)
fwrite(flaws_and_outcomes_dt,file.path(project_path,paste0(project_name,"-flaws_vs_outcome_metrics.csv")))
```

